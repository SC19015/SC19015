---
title: "Homework3"
author: '19015'
date: "2019/10/23"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{A-19015-2019-10-18}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Questions
+ 1 Suppose a 95% symmetric t-interval is applied to estimate a mean, but the sample data are non-normal. Then the probability that the confidence interval covers the mean is not necessarily equal to 0.95. Use a Monte Carlo experiment to estimate the coverage probability of the t-interval for random samples of $\chi^2$(2) data with sample size n = 20. Compare your t-interval results with the simulation results in Example 6.4. (The t-interval should be more robust to departures from normality than the interval for variance.)

+ 2 Estimate the 0.025, 0.05, 0.95, and 0.975 quantiles of the skewness $\sqrt b_1$ under normality by a Monte Carlo experiment. Compute the standard error of the estimates from (2.14) using the normal approximation for the density (with exact variance formula). Compare the estimated quantiles with the quantiles of the large sample approximation $\sqrt b_1 \quad \approx$  N(0, 6/n).

## Answers

### 1

+ Give 1000 simulations of whether the confidence interval of t-interval covers the mean. And use  Monte Carlo experiment to estimate.(True mean is 2)
```{r}
  load('A-19015-2019-10-18.RData')
#   set.seed(123)
#   n<-20
#   c<-qt(0.975,n-1) # 0.975 quantile of t-distribution
# cv.t<-sapply(1:1000,FUN= function(o){
#   x<-rchisq(n,2)
#   m<-mean(x) # estimate of mean
#   se<-sqrt(var(x)) # estimate of standard error
#   as.numeric((m-c*se/sqrt(n)<2)&(m+c*se/sqrt(n)>2)) # ci
# })
mean(cv.t) # mean of  Monte Carlo experiment
```

+ We can the probability is not equal to 0.95, is less than 0.95. The Example 6.4 used the chi-square distribution to estimate the variance (True is 4).
```{r}
  # alpha <- .05
  # UCL <- replicate(1000, expr = {
  # x <- rchisq(n,2)
  # (n-1) * var(x) / qchisq(alpha, df = n-1)
  # } )
#count the number of intervals that contain sigma^2=4
sum(UCL > 4)/1000
```

+ We can see the result is far less than 0.95 , so t-interval is more robust.

### 2 
+ Generate the skewness of 1000 samples of N(0,1),n=100.
```{r}
# n2<-100
# res<-sapply(1:1000,FUN = function(o){
#   x<-rnorm(n2)
#   m<-mean(x)
#   s<-var(x)
#   bs<-mean((x-m)^3)/s^(1.5)
# })
```

+ Give the quantiles of the sample.
```{r}
  # q<-quantile(res,probs = seq(0, 1, 0.025))[c(2,3,39,40)]
q
```

+ The variance of the q sample quantile [63, 2.7] is
$$\operatorname{Var}\left(\hat{x}_{q}\right)=\frac{q(1-q)}{n f\left(x_{q}\right)^{2}}$$
We assume $\sqrt b_1 \sim$ N(0,6/n) so we have 
```{r}
# p<-c(0.025,0.05,0.95,0.975)
# d<-dnorm(q,0,6/n) # Compute the density of q as N(0,6/n)
# vq<-(1-p)*p/(n*d^2) # compute the variance using the formula above
sqrt(vq)
```

+ Compare the estimated quantiles with the quantiles of the large sample approximation $\sqrt b_1 \quad \approx$  N(0, 6/n).
```{r}
#  q.real<-qnorm(p,0,6/n)
# out<-data.frame(rbind(q,q.real),row.names = c("Estimates","True value"))
knitr::kable(out)
```
