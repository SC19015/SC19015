---
title: "Homework"
author: '19015'
date: "2019/11/7"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{A-19015-2019-11-01}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Questions

### 6.7
+ Estimate the power of the skewness test of normality against symmetric Beta($\alpha$, $\alpha$) distributions and comment on the results. Are the results different for heavy-tailed symmetric alternatives such as t(ν)?

### 6.A

+ Use Monte Carlo simulation to investigate whether the empirical Type I error rate of the t-test is approximately equal to the nominal significance level $\alpha$, when the sampled population is non-normal. The t-test is robust to mild departures from normality. Discuss the simulation results for the cases where the sampled population is (i) $\chi^2$(1), (ii) Uniform(0,2), and (iii) Exponential(rate=1). In each case, test H0 : $\mu = \mu_0$ vs H1 :$\mu \neq \mu_0$, where µ0 is the mean of $\chi^2$(1), Uniform(0,2), and Exponential(1), respectively.

### Discusssion

+ If we obtain the powers for two methods under a particular simulation setting with 10,000 experiments: say, 0.651 for one method and 0.676 for another method. Can we say the powers are different at 0.05 level?
   + What is the corresponding hypothesis test problem?
   + What test should we use? Z-test, two-sample t-test, paired-t test or McNemar test?
   + What information is needed to test your hypothesis?
   

## Answers

### 6.7

+ Set skewness function.
```{r}
load("A-19015-2019-11-1.RData")
# sk <- function(x) {
#   #computes the sample skewness coeff.
#   xbar <- mean(x)
#   m3 <- mean((x - xbar)^3)
#   m2 <- mean((x - xbar)^2)
#   return( m3 / m2^1.5 )
# }
```

+ We estimate by simulation the power of the skewness test of beta distribution against a contaminated beta alternative.The contaminated beta distribution is denoted by $(1-\epsilon)$Beta(2,2)+$\epsilon$Beta(100,100).
```{r}
# n <- 50
# m <- 2500
# epsilon <- c(seq(0, .15, .01), seq(.15, 1, .05))
# N <- length(epsilon)
# pwr.beta <- numeric(N)
# pwr.t <- numeric(N)
# #critical value for the skewness test
# cv <- qnorm(0.975, 0, sqrt(6 / n))
# for (j in 1:N) { #for each epsilon
#   e <- epsilon[j]
#   sktests <- numeric(m)
#   for (i in 1:m) { #for each replicate
#     a <- rbinom(n,1,prob = 1-e)
#     x <- rbeta(n, 2, 2)*a+rbeta(n,100, 100)*(1-a)
#     sktests[i] <- as.integer(abs(sk(x)) >= cv)
#   }
#   pwr.beta[j] <- mean(sktests)
# }
```

+ We estimate by simulation the power of the skewness test of t distribution against a contaminated t alternative.The contaminated t distribution is denoted by $(1-\epsilon)$t(5)+$\epsilon$t(10).
```{r}
# for (j in 1:N) { #for each epsilon
#   e <- epsilon[j]
#   sktests <- numeric(m)
#   for (i in 1:m) { #for each replicate
#     a <- rbinom(n,1,prob = 1-e)
#     x <- rt(n, 5)*a+rt(n, 10)*(1-a)
#     sktests[i] <- as.integer(abs(sk(x)) >= cv)
#   }
#   pwr.t[j] <- mean(sktests)
# }
```

+ Show the results.
```{r}
#plot power vs epsilon
plot(epsilon, pwr.beta, type = "l",
     xlab = bquote(epsilon), ylim = c(0,1),ylab = "power")
lines(epsilon, pwr.t,col = "red")
legend("topright",legend=c("beta","t"),col=c("black","red"),lty=1,lwd=2) 

```

+ We can see the Type-I error is not controled very well for a  heavy-tailed symmetric alternative such as t(5).

### 6.A
```{r}
# num<-c(50,100,200,500,1000) # Estimate the Type-I error for different sizes.
# m<-10000
# 
# er<-NULL
# for (n in num){
#   cv<-qt(0.975,n-1)
#   er1<-mean(sapply(1:m,FUN = function(o){
#   x<-rchisq(n,1)
#   m<-mean(x)
#   se<-sqrt(var(x))
#   abs((m-1)*sqrt(n)/se)>=cv
#   }))  # Estimate the Type-I error for chi-square distribution
#   er2<-mean(sapply(1:m,FUN = function(o){
#   x<-runif(n,0,2)
#   m<-mean(x)
#   se<-sqrt(var(x))
#   abs((m-1)*sqrt(n)/se)>=cv
#   }))   # Estimate the Type-I error for uniform distribution
#   er3<-mean(sapply(1:m,FUN = function(o){
#   x<-rexp(n,1)
#   m<-mean(x)
#   se<-sqrt(var(x))
#   abs((m-1)*sqrt(n)/se)>=cv
#   }))  # Estimate the Type-I error for exp distribution
#   er<-cbind(er,c(er1,er2,er3))
# }
# colnames(er)<-num
# rownames(er)<-c("chi(1)","U(0,2)","exp(1)")
knitr::kable(er)
```

+ From the figure, we can see The t-test is robust to mild departures from normality. When n gets larger , the Type-I error gets closer to the true $\alpha$.

### Discussion

+  Let the tests be T1 and T2.The power of Ti denotes $\pi_i$,i = 1,2. So the hypothesis test problem is H0: $\pi_1 = \pi_2$, H1: $\pi_1 \neq \pi_2$. So for each simulation the outcome is a binomial experiment. So we could use pair-t test or Mcnemar test. We also should know whether the null hypothesis was rejected under two tests for each simulation.
